import torch
import numpy as np
from matplotlib import pyplot as plt
from torch.utils.data import DataLoader
from torchvision import datasets
from torchvision import transforms
import torch.nn.functional as F
#super parameter
batch_size=64
learnig_rate=0.01
momentum=0.5
EPOCH=10
#prepare datasets
#transforms.Compose([action1,action2,action3]) Normalize(mean,std)
transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,),(0.3081))])
#data set
train_dataset=datasets.MNIST(root=".data/minist",train=True,transform=transform,download=True)
test_dataset=datasets.MNIST(root=".data/minist",train=False,transform=transform,download=True)
train_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True)
test_loader=DataLoader(test_dataset,batch_size=batch_size,shuffle=False)
#plot #one time plot 12 figs 
fig=plt.figure()
for i in range(12):
    plt.subplot(3,4,i+1)#NONE is a blank value,"none"is str,blank value will set!
    plt.imshow(np.random.rand(10,10),cmap="gray",interpolation="none")
    plt.title("label:{}".format(train_dataset.targets[i]))
    plt.xticks([])#clean the xticks
    plt.yticks([])#clean the yticks
plt.show()
#design model using class
#class super # init initialize
class Net(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1=torch.nn.Sequential(
            torch.nn.Conv2d(1,10,kernel_size=5),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(kernel_size=2),
        )
        self.conv2=torch.nn.Sequential(
            torch.nn.Conv2d(10,20,kernel_size=5),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(kernel_size=2)
        )
        self.fc=torch.nn.Sequential(
            torch.nn.Linear(320,50),
            torch.nn.Linear(50,10),
        )
    def forward(self,x):
        batch_size=x.size(0)
        x=self.conv1(x)
        x=self.conv2(x)
        x=x.view(batch_size,-1)
        x=self.fc(x)
        return x

model=Net()
#Construct loss and optimizer
criterion=torch.nn.CrossEntropyLoss()
optimizer=torch.optim.SGD(model.parameters(),lr=learnig_rate,momentum=momentum)
#Train and Test Class
def train(epoch):
    running_loss=0.0
    running_total=0
    running_correct=0
    for batch_idx,data in enumerate(train_loader,0):
        input,target=data
        optimizer.zero_grad()
        #forward+backward+update
        output=model(input)
        loss=criterion(output,target)
        loss.backward()
        optimizer.step()
#tensor----float（item）
        running_loss+=loss.item()
        #max return max_value,max_index# dim=0 dim=1
        _,predicted=torch.max(output.data,dim=1)
        running_total+=input.shape[0]
        running_correct+=(predicted==target).sum().item()
        #Every 300 times print once
        if batch_idx%300==299:
            print("[%d,%5d]:loss: %.3f,acc:%.2f %%"
                  %(epoch+1,batch_idx+1,running_loss / 300,100*running_correct/running_total))
            running_loss=0.0
            running_total=0
            running_correct=0
            # torch.save(model.state_dict(), './model_Mnist.pth')
            # torch.save(optimizer.state_dict(), './optimizer_Mnist.pth')

#Test
def test():
    crorrect=0
    total=0
    with torch.no_grad():   #close grad
        for data in test_loader:
             images,labels=data
             outputs= model(images)
             _,predicted=torch.max(outputs.data,dim=1)
             total+=labels.size(0)#sum total
             crorrect+=(predicted==labels).sum().item()
    acc=crorrect/total
    print("[%d/%d]:Accuracy on test set: %.1f %%" % (epoch+1,EPOCH,100*acc))
    return acc
#main function ,only python .py can work
#start train and test
if __name__== "__main__":
    acc_list_test=[]
    for epoch in range(EPOCH):
        train(epoch)
        acc_test=test()
        acc_list_test.append(acc_test)
    plt.plot(acc_list_test)
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy On TestSet")
    plt.show()
